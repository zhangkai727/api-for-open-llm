version: '3.10'

services:
  apiserver:
    image: llm-api:pytorch
    command: python api/server.py
    ulimits:
      stack: 67108864
      memlock: -1
    environment:
      - PORT=8000
<<<<<<< HEAD
      - MODEL_NAME=qwen
      - MODEL_PATH=checkpoints/qwen-7b-chat
      - EMBEDDING_NAME=checkpoints/m3e-base
=======
      - MODEL_NAME=qwen2
      - PROMPT_NAME=qwen2
      - MODEL_PATH=checkpoints/Qwen2-7B-Instruct
#      - EMBEDDING_NAME=checkpoints/bce-embedding-base_v1
>>>>>>> d45db7c71cc1d7c6f454aab8dc32da6b0299ee3d
      - DEVICE_MAP=auto
    volumes:
      - $PWD:/workspace
      # model path need to be specified if not in pwd
#      - /data/checkpoints:/workspace/checkpoints
    env_file:
      - .env.example
    ports:
      - "7891:8000"
    restart: always
    networks:
      - apinet
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # 指定gpu
              capabilities: [gpu]

networks:
  apinet:
    driver: bridge
    name: apinet